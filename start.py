#!/usr/bin/env python3
"""
Startup script for Obsidian Vector Search API
"""
import sys
import os
import asyncio
from pathlib import Path

# Add current directory to Python path
sys.path.insert(0, str(Path(__file__).parent))

from config import get_settings

def check_requirements():
    """Check if all requirements are met"""
    try:
        settings = get_settings()
    except Exception as e:
        print(f"âŒ Configuration error: {e}")
        print("ğŸ’¡ Make sure to create a .env file with required settings")
        print("ğŸ“‹ Copy .env.example to .env and update the values")
        return False

    # Check vault path
    if not Path(settings.vault_path).exists():
        print(f"âŒ Vault path does not exist: {settings.vault_path}")
        print("ğŸ’¡ Update VAULT_PATH in your .env file")
        return False

    print(f"âœ… Vault path: {settings.vault_path}")
    print(f"âœ… Ollama URL: {settings.ollama_url}")
    print(f"âœ… Embedding model: {settings.embedding_model}")
    print(f"âœ… API will run on: http://{settings.api_host}:{settings.api_port}")

    return True

async def test_ollama_connection():
    """Test connection to Ollama"""
    from ollama_client import OllamaEmbeddingClient

    settings = get_settings()
    client = OllamaEmbeddingClient(settings.ollama_url, settings.embedding_model)

    try:
        health = await client.health_check()
        if health:
            print("âœ… Ollama server is accessible")

            model_exists = await client.check_model_exists()
            if model_exists:
                print(f"âœ… Embedding model '{settings.embedding_model}' is available")
            else:
                print(f"âš ï¸  Embedding model '{settings.embedding_model}' not found")
                print(f"ğŸ’¡ Run: ollama pull {settings.embedding_model}")
                return False
        else:
            print("âŒ Cannot connect to Ollama server")
            print("ğŸ’¡ Make sure Ollama is running and accessible")
            return False

    except Exception as e:
        print(f"âŒ Ollama connection error: {e}")
        return False
    finally:
        await client.close()

    return True

def main():
    """Main startup function"""
    print("ğŸš€ Starting Obsidian Vector Search API...")
    print("=" * 50)

    # Check requirements
    if not check_requirements():
        sys.exit(1)

    # Test Ollama connection
    print("\nğŸ” Testing Ollama connection...")
    if not asyncio.run(test_ollama_connection()):
        sys.exit(1)

    print("\nâœ… All checks passed! Starting the API server...")
    print("=" * 50)

    # Start the API server
    import uvicorn
    from main import app

    settings = get_settings()

    try:
        uvicorn.run(
            app,
            host=settings.api_host,
            port=settings.api_port,
            log_level="info"
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Goodbye!")
    except Exception as e:
        print(f"âŒ Server error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()